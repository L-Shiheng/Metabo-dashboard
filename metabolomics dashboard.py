import streamlit as st
import pandas as pd
import numpy as np
from scipy import stats
import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.cross_decomposition import PLSRegression
from sklearn.preprocessing import StandardScaler
from statsmodels.stats.multitest import multipletests

# ==========================================
# 0. å…¨å±€é…ç½®ä¸é£æ ¼è®¾ç½® (Publication Ready)
# ==========================================
st.set_page_config(page_title="MetaboAnalyst Pro", page_icon="ğŸ”¬", layout="wide")

# CSS: è°ƒæ•´å­—ä½“å’Œå¸ƒå±€ï¼Œä½¿å…¶æ›´åƒä¸“ä¸šè½¯ä»¶
st.markdown("""
<style>
    .block-container {padding-top: 1rem; padding-bottom: 3rem;}
    h1, h2, h3 {font-family: 'Arial', sans-serif;}
    .stAlert {font-weight: bold;}
</style>
""", unsafe_allow_html=True)

# å®šä¹‰å­¦æœ¯å¸¸ç”¨çš„é…è‰²æ–¹æ¡ˆ (MetaboAnalyst é£æ ¼: çº¢/ç»¿ æˆ– çº¢/è“)
COLOR_PALETTE = {
    'Up': '#CD0000',      # æ·±çº¢
    'Down': '#008B00',    # æ·±ç»¿ (æˆ–æ”¹ä¸º '#00008B' æ·±è“)
    'NS': '#D3D3D3'       # æµ…ç°
}

# Plotly ç»Ÿä¸€æ¨¡æ¿å‡½æ•°ï¼šè®©æ‰€æœ‰äº¤äº’å›¾çœ‹èµ·æ¥åƒæ‰“å°å‡ºæ¥çš„æ–‡ç« æ’å›¾
def update_layout_pub(fig, title="", x_title="", y_title=""):
    fig.update_layout(
        template="simple_white", # çº¯ç™½èƒŒæ™¯ï¼Œæ— ç½‘æ ¼
        title={
            'text': title,
            'y':0.95, 'x':0.5,
            'xanchor': 'center', 'yanchor': 'top',
            'font': dict(size=18, color='black', family="Arial, bold")
        },
        xaxis=dict(title=x_title, showline=True, linewidth=1.5, linecolor='black', mirror=True),
        yaxis=dict(title=y_title, showline=True, linewidth=1.5, linecolor='black', mirror=True),
        font=dict(family="Arial", size=14, color="black"),
        width=800, height=600,
        margin=dict(l=60, r=40, t=60, b=60)
    )
    return fig

# ==========================================
# 1. æ ¸å¿ƒè®¡ç®—å‡½æ•° (å«é€šè·¯æ•°æ®åº“)
# ==========================================

# --- å†…ç½®å¾®å‹é€šè·¯æ•°æ®åº“ (ä»…ä½œæ¼”ç¤ºï¼ŒçœŸå®åˆ†æéœ€è¿æ¥ KEGG API) ---
PATHWAY_DB = {
    "Glycolysis / Gluconeogenesis": ["Glucose", "Pyruvate", "Lactate", "Hexokinase", "Fructose-6P", "G3P"],
    "Citrate Cycle (TCA cycle)": ["Citrate", "Succinate", "Fumarate", "Malate", "Oxaloacetate", "Pyruvate", "Acetyl-CoA"],
    "Pyruvate Metabolism": ["Pyruvate", "Lactate", "Acetyl-CoA", "Acetate", "Acetaldehyde"],
    "Alanine, Aspartate and Glutamate": ["Alanine", "Aspartate", "Glutamate", "Glutamine", "Pyruvate", "Oxaloacetate"],
    "Glycerolipid Metabolism": ["Glycerol", "Triglyceride", "G3P", "Fatty Acid"],
    "Fatty Acid Biosynthesis": ["Acetyl-CoA", "Malonyl-CoA", "Fatty Acid", "Pyruvate"]
}

@st.cache_data
def run_pathway_analysis(significant_metabolites, all_metabolites_in_study):
    """
    æ‰§è¡Œç®€æ˜“çš„é€šè·¯å¯Œé›†åˆ†æ (Fisher Exact Test / Hypergeometric Test)
    """
    results = []
    # ç®€å•çš„æ¨¡ç³ŠåŒ¹é…ï¼šåªè¦åˆ—åé‡ŒåŒ…å«å…³é”®å­—å°±ç®—åŒ¹é…
    sig_set = set([m.lower() for m in significant_metabolites])
    bg_set = set([m.lower() for m in all_metabolites_in_study])
    
    for pathway_name, compounds in PATHWAY_DB.items():
        path_set = set([c.lower() for c in compounds])
        
        # a: æ—¢åœ¨é€šè·¯é‡Œï¼Œåˆæ˜¾è‘—çš„ (Hit)
        hits = sig_set.intersection(path_set)
        a = len(hits)
        
        # b: åœ¨é€šè·¯é‡Œï¼Œä½†ä¸æ˜¾è‘—
        b = len(path_set) - a
        
        # c: ä¸åœ¨é€šè·¯é‡Œï¼Œä½†æ˜¾è‘—
        c = len(sig_set) - a
        
        # d: æ—¢ä¸åœ¨é€šè·¯é‡Œï¼Œä¹Ÿä¸æ˜¾è‘— (èƒŒæ™¯å™ªéŸ³)
        # ä¼°ç®—æ€»èƒŒæ™¯åº“å¤§å°ï¼Œè¿™é‡Œå‡è®¾ä¸€ä¸ªå¸¸è§çš„äººç±»ä»£è°¢ç‰©åº“å¤§å°ä¸º 300
        total_genome = 300 
        d = total_genome - a - b - c
        
        if a > 0: # åªæœ‰å‘½ä¸­çš„é€šè·¯æ‰è®¡ç®—
            oddsratio, pvalue = stats.fisher_exact([[a, b], [c, d]], alternative='greater')
            results.append({
                'Pathway': pathway_name,
                'Hits': a,
                'P_Value': pvalue,
                '-Log10_P': -np.log10(pvalue) if pvalue > 0 else 0,
                'Impact': a / len(path_set) # ç®€æ˜“ Impact è®¡ç®—
            })
            
    return pd.DataFrame(results)

@st.cache_data
def preprocess_data(df, group_col, log_transform=True):
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if group_col in numeric_cols: numeric_cols.remove(group_col)
    meta_cols = [c for c in df.columns if c not in numeric_cols]
    
    data_df = df[numeric_cols].copy()
    if data_df.isnull().sum().sum() > 0:
        data_df.fillna(data_df.min().min() * 0.5, inplace=True)
    if log_transform:
        data_df = np.log2(data_df + 1)
        
    return pd.concat([df[meta_cols], data_df], axis=1), numeric_cols

def calculate_vips(model):
    t = model.x_scores_; w = model.x_weights_; q = model.y_loadings_
    p, h = w.shape; vips = np.zeros((p,))
    s = np.diag(t.T @ t @ q.T @ q).reshape(h, -1)
    total_s = np.sum(s)
    for i in range(p):
        weight = np.array([(w[i, j] / np.linalg.norm(w[:, j]))**2 for j in range(h)])
        vips[i] = np.sqrt(p * (s.T @ weight) / total_s)
    return vips

@st.cache_data
def run_statistics(df, group_col, case, control, features):
    g1 = df[df[group_col] == case]
    g2 = df[df[group_col] == control]
    res = []
    for f in features:
        v1, v2 = g1[f].values, g2[f].values
        fc = np.mean(v1) - np.mean(v2)
        try: t, p = stats.ttest_ind(v1, v2, equal_var=False)
        except: p = 1.0
        res.append({'Metabolite': f, 'Log2_FC': fc, 'P_Value': p})
    
    res_df = pd.DataFrame(res)
    res_df = res_df.dropna()
    _, p_corr, _, _ = multipletests(res_df['P_Value'], method='fdr_bh')
    res_df['FDR'] = p_corr
    res_df['-Log10_P'] = -np.log10(res_df['P_Value'])
    return res_df

# ==========================================
# 2. ç•Œé¢é€»è¾‘
# ==========================================
with st.sidebar:
    st.title("ğŸ§ª MetaboAnalyst Pro")
    uploaded_file = st.file_uploader("ä¸Šä¼  CSV æ•°æ®", type=["csv"])
    if not uploaded_file:
        st.info("è¯·ä¸Šä¼  CSVã€‚æ ¼å¼ï¼šè¡Œ(æ ·æœ¬) x åˆ—(ä»£è°¢ç‰©)ã€‚éœ€åŒ…å«åˆ†ç»„åˆ—ã€‚")
        st.stop()
        
    raw_df = pd.read_csv(uploaded_file)
    non_num = raw_df.select_dtypes(exclude=[np.number]).columns.tolist()
    if not non_num: st.stop()
    
    group_col = st.selectbox("åˆ†ç»„åˆ—", non_num)
    grps = raw_df[group_col].unique()
    if len(grps) < 2: st.stop()
    
    case = st.selectbox("Case (Exp)", grps, index=0)
    ctrl = st.selectbox("Control", grps, index=1)
    
    st.divider()
    st.markdown("### âš™ï¸ ç»Ÿè®¡å‚æ•°")
    p_th = st.number_input("P-value Cutoff", 0.05, format="%.3f")
    fc_th = st.number_input("Log2 FC Cutoff", 1.0)
    
# æ•°æ®å¤„ç†
df_proc, feats = preprocess_data(raw_df, group_col)
df_sub = df_proc[df_proc[group_col].isin([case, ctrl])].copy()
res_stats = run_statistics(df_sub, group_col, case, ctrl, feats)

# æ ‡è®°æ˜¾è‘—æ€§
res_stats['Sig'] = 'NS'
res_stats.loc[(res_stats['P_Value'] < p_th) & (res_stats['Log2_FC'] > fc_th), 'Sig'] = 'Up'
res_stats.loc[(res_stats['P_Value'] < p_th) & (res_stats['Log2_FC'] < -fc_th), 'Sig'] = 'Down'

# æå–æ˜¾è‘—ç‰¹å¾åˆ—è¡¨
sig_metabolites = res_stats[res_stats['Sig'] != 'NS']['Metabolite'].tolist()

# ==========================================
# 3. ç»“æœå±•ç¤º (äº”å¤§æ¨¡å—)
# ==========================================
st.header(f"ğŸ“Š åˆ†ææŠ¥å‘Š: {case} vs {ctrl}")
tabs = st.tabs(["PCA / PLS-DA", "ğŸŒ‹ ç«å±±å›¾", "ğŸ”¥ èšç±»çƒ­å›¾", "ğŸ§¬ é€šè·¯å¯Œé›†", "ğŸ“‘ æ•°æ®è¡¨"])

# --- Tab 1: å¤šå˜é‡åˆ†æ (PCA & PLS-DA) ---
with tabs[0]:
    col1, col2 = st.columns(2)
    X = StandardScaler().fit_transform(df_sub[feats])
    
    # PCA
    with col1:
        pca = PCA(n_components=2).fit(X)
        pcs = pca.transform(X)
        var = pca.explained_variance_ratio_
        fig_pca = px.scatter(x=pcs[:,0], y=pcs[:,1], color=df_sub[group_col],
                             width=600, height=500)
        # æ‰‹åŠ¨ç¾åŒ–ç‚¹çš„å¤§å°å’Œè¾¹æ¡†
        fig_pca.update_traces(marker=dict(size=12, line=dict(width=1, color='black')))
        update_layout_pub(fig_pca, "PCA Score Plot", f"PC1 ({var[0]:.1%})", f"PC2 ({var[1]:.1%})")
        st.plotly_chart(fig_pca, use_container_width=True)

    # PLS-DA
    with col2:
        pls = PLSRegression(n_components=2).fit(X, pd.factorize(df_sub[group_col])[0])
        pls_scores = pls.x_scores_
        fig_pls = px.scatter(x=pls_scores[:,0], y=pls_scores[:,1], color=df_sub[group_col],
                             width=600, height=500)
        fig_pls.update_traces(marker=dict(size=12, line=dict(width=1, color='black')))
        update_layout_pub(fig_pls, "PLS-DA Score Plot", "Component 1", "Component 2")
        st.plotly_chart(fig_pls, use_container_width=True)

# --- Tab 2: ç«å±±å›¾ (MetaboAnalyst Style) ---
with tabs[1]:
    # é¢œè‰²æ˜ å°„
    color_map = {
        'Up': COLOR_PALETTE['Up'], 
        'Down': COLOR_PALETTE['Down'], 
        'NS': COLOR_PALETTE['NS']
    }
    
    fig_vol = px.scatter(res_stats, x="Log2_FC", y="-Log10_P", color="Sig",
                         color_discrete_map=color_map,
                         hover_data=["Metabolite", "P_Value"],
                         width=800, height=600)
    
    # å¢åŠ é˜ˆå€¼çº¿
    fig_vol.add_hline(y=-np.log10(p_th), line_dash="dash", line_color="black", opacity=0.5)
    fig_vol.add_vline(x=fc_th, line_dash="dash", line_color="black", opacity=0.5)
    fig_vol.add_vline(x=-fc_th, line_dash="dash", line_color="black", opacity=0.5)
    
    # æ ·å¼è°ƒæ•´
    fig_vol.update_traces(marker=dict(size=10, opacity=0.8, line=dict(width=1, color='black')))
    update_layout_pub(fig_vol, "Volcano Plot", "Log2 Fold Change", "-Log10(P-value)")
    
    st.plotly_chart(fig_vol, use_container_width=True)
    st.caption("æç¤ºï¼šé¼ æ ‡æ‚¬åœå³ä¸Šè§’ç›¸æœºå›¾æ ‡å¯ä¸‹è½½ SVG/PNG çŸ¢é‡å›¾ç”¨äºå‘è¡¨ã€‚")

# --- Tab 3: èšç±»çƒ­å›¾ (Seaborn Implementation) ---
with tabs[2]:
    st.subheader("Top 25 æ˜¾è‘—å·®å¼‚ä»£è°¢ç‰©çƒ­å›¾")
    
    if len(sig_metabolites) < 2:
        st.warning("æ˜¾è‘—å·®å¼‚ä»£è°¢ç‰©å¤ªå°‘ï¼Œæ— æ³•ç»˜åˆ¶çƒ­å›¾ã€‚è¯·å°è¯•æ”¾å®½ P å€¼æˆ– FC é˜ˆå€¼ã€‚")
    else:
        # 1. å‡†å¤‡æ•°æ®ï¼šå–å‰25ä¸ªæœ€æ˜¾è‘—çš„ï¼ˆæŒ‰På€¼æ’åºï¼‰
        top_n = 25
        top_feats = res_stats.sort_values('P_Value').head(top_n)['Metabolite'].tolist()
        
        hm_data = df_sub.set_index(group_col)[top_feats]
        
        # ä¸ºäº†ç”»å›¾å¥½çœ‹ï¼Œæˆ‘ä»¬åœ¨è¡Œï¼ˆæ ·æœ¬ï¼‰ä¸ŠåŠ é¢œè‰²æ¡æ¥åŒºåˆ†ç»„åˆ«
        # åˆ›å»ºä¸€ä¸ªé¢œè‰²æ˜ å°„å­—å…¸
        lut = dict(zip(df_sub[group_col].unique(), "rbg"))
        row_colors = df_sub[group_col].map(lut)
        
        # 2. ç»˜åˆ¶ Seaborn Clustermap
        # z_score=1 è¡¨ç¤ºæŒ‰åˆ—ï¼ˆä»£è°¢ç‰©ï¼‰è¿›è¡Œæ ‡å‡†åŒ–ï¼Œè¿™æ˜¯çƒ­å›¾çš„æ ‡å‡†åšæ³•
        try:
            g = sns.clustermap(hm_data.astype(float), 
                               z_score=1, 
                               cmap="vlag",  # çº¢-ç™½-è“ ç»å…¸å­¦æœ¯é…è‰² (vlag or RdBu_r)
                               center=0, 
                               row_colors=row_colors,
                               figsize=(10, 8),
                               dendrogram_ratio=(.1, .2),
                               cbar_pos=(.02, .32, .03, .2))
            
            # è°ƒæ•´å­—ä½“
            plt.setp(g.ax_heatmap.get_xticklabels(), rotation=45, ha="right", fontsize=10)
            plt.setp(g.ax_heatmap.get_yticklabels(), visible=False) # éšè—æ ·æœ¬åï¼Œé˜²æ­¢å¤ªä¹±
            
            st.pyplot(g.fig) # æ˜¾ç¤º Matplotlib å›¾
            
        except Exception as e:
            st.error(f"ç»˜å›¾å‡ºé”™ (é€šå¸¸æ˜¯å› ä¸ºæ•°æ®é‡å¤ªå°): {e}")

# --- Tab 4: é€šè·¯å¯Œé›†åˆ†æ (Pathway Analysis) ---
with tabs[3]:
    st.subheader("ğŸ§¬ ä»£è°¢é€šè·¯å¯Œé›† (æ¼”ç¤ºç‰ˆ)")
    
    # è¿è¡Œé€šè·¯åˆ†æ
    path_res = run_pathway_analysis(sig_metabolites, feats)
    
    if path_res.empty:
        st.warning(f"æœªæ‰¾åˆ°æ˜¾è‘—å¯Œé›†çš„é€šè·¯ã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºæ¼”ç¤ºæ•°æ®åº“è¾ƒå°ï¼Œæˆ–è€…æ‚¨çš„ä»£è°¢ç‰©å‘½åä¸æ•°æ®åº“ä¸åŒ¹é…ã€‚\n\n**æ¼”ç¤ºæ”¯æŒçš„ä»£è°¢ç‰©å**: Glucose, Pyruvate, Lactate, Citrate, Alanine ç­‰ã€‚")
    else:
        # ç»˜åˆ¶æ°”æ³¡å›¾ (Bubble Plot)
        # X: Impact, Y: -Log10(P), Size: Hits, Color: P-value
        fig_path = px.scatter(path_res, x="Impact", y="-Log10_P",
                              size="Hits", color="P_Value",
                              hover_name="Pathway",
                              size_max=40,
                              color_continuous_scale="Reds_r", # På€¼è¶Šå°è¶Šçº¢
                              width=800, height=500)
        
        update_layout_pub(fig_path, "Pathway Enrichment Analysis", "Pathway Impact", "-Log10(P-value)")
        
        # å¢åŠ æ–‡æœ¬æ ‡ç­¾
        fig_path.update_traces(textposition='top center')
        
        st.plotly_chart(fig_path, use_container_width=True)
        
        st.dataframe(path_res)
        st.info("âš ï¸ æ³¨æ„ï¼šæ­¤æ¨¡å—ä½¿ç”¨å†…ç½®çš„å°å‹æ¼”ç¤ºæ•°æ®åº“ã€‚è¿›è¡Œæ­£å¼å‘è¡¨åˆ†ææ—¶ï¼Œè¯·åŠ¡å¿…ä½¿ç”¨å®Œæ•´çš„ KEGG æˆ– SMPDB æ•°æ®åº“ã€‚")

# --- Tab 5: æ•°æ®ä¸‹è½½ ---
with tabs[4]:
    st.subheader("ğŸ“¥ å¯¼å‡ºåˆ†æç»“æœ")
    csv = res_stats.to_csv(index=False).encode('utf-8')
    st.download_button("ä¸‹è½½ç»Ÿè®¡ç»“æœ (CSV)", csv, "results.csv", "text/csv")
