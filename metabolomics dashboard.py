import streamlit as st
import pandas as pd
import numpy as np
from scipy import stats
import plotly.express as px
from sklearn.decomposition import PCA
from sklearn.cross_decomposition import PLSRegression
from sklearn.preprocessing import StandardScaler
from statsmodels.stats.multitest import multipletests

# ==========================================
# 1. é¡µé¢åŸºæœ¬é…ç½®
# ==========================================
st.set_page_config(
    page_title="MetaboAnalyst-Lite",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ç®€å•çš„ CSS ä¼˜åŒ–ï¼Œå‡å°‘é¡¶éƒ¨ç•™ç™½
st.markdown("""
<style>
    .block-container {padding-top: 1rem; padding-bottom: 2rem;}
    h1 {font-size: 1.8rem !important;}
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. æ ¸å¿ƒè®¡ç®—å‡½æ•°åº“
# ==========================================

@st.cache_data
def preprocess_data(df, group_col, log_transform=True):
    """
    æ•°æ®æ¸…æ´—ä¸é¢„å¤„ç†
    - è‡ªåŠ¨è¯†åˆ«æ•°å€¼åˆ—
    - å¯é€‰ Log2 è½¬æ¢
    """
    # æå–æ•°å€¼åˆ—ï¼ˆä»£è°¢ç‰©ï¼‰å’Œå…ƒæ•°æ®åˆ—ï¼ˆåˆ†ç»„ç­‰ï¼‰
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    # æ’é™¤æ‰å¯èƒ½è¢«è¯¯åˆ¤ä¸ºæ•°å€¼çš„ Group åˆ—ï¼ˆå¦‚æœæ˜¯æ•°å­—ç¼–ç ï¼‰
    if group_col in numeric_cols:
        numeric_cols.remove(group_col)
        
    meta_cols = [c for c in df.columns if c not in numeric_cols]
    
    data_df = df[numeric_cols].copy()
    meta_df = df[meta_cols].copy()
    
    # ç®€å•çš„ç¼ºå¤±å€¼å¡«å…… (ç”¨æœ€å°å€¼çš„ä¸€åŠå¡«å……ï¼Œæ¨¡æ‹Ÿæ£€æµ‹é™)
    if data_df.isnull().sum().sum() > 0:
        data_df.fillna(data_df.min().min() * 0.5, inplace=True)
    
    if log_transform:
        # Log2(x+1) é¿å… log(0)
        data_df = np.log2(data_df + 1)
        
    return pd.concat([meta_df, data_df], axis=1), numeric_cols

@st.cache_data
def calculate_vips(model):
    """
    æ‰‹åŠ¨è®¡ç®— PLS-DA çš„ VIP å€¼ (Variable Importance in Projection)
    Scikit-learn ä¸ç›´æ¥æä¾›æ­¤å±æ€§ã€‚
    """
    t = model.x_scores_
    w = model.x_weights_
    q = model.y_loadings_
    p, h = w.shape
    vips = np.zeros((p,))
    s = np.diag(t.T @ t @ q.T @ q).reshape(h, -1)
    total_s = np.sum(s)
    
    for i in range(p):
        weight = np.array([(w[i, j] / np.linalg.norm(w[:, j]))**2 for j in range(h)])
        vips[i] = np.sqrt(p * (s.T @ weight) / total_s)
        
    return vips

@st.cache_data
def run_statistics(df, group_col, case_group, control_group, feature_cols):
    """
    æ‰§è¡Œå•å› ç´ ç»Ÿè®¡åˆ†æ: T-test, Fold Change, FDR
    """
    # æå–ä¸¤ç»„æ•°æ®
    group_case = df[df[group_col] == case_group]
    group_ctrl = df[df[group_col] == control_group]
    
    results = []
    
    for feature in feature_cols:
        vals_case = group_case[feature].values
        vals_ctrl = group_ctrl[feature].values
        
        # 1. Fold Change (Log2 scale)
        # å‡è®¾æ•°æ®å·² Log2 åŒ–ï¼Œå·®å€¼å³ä¸º Log2FC
        mean_case = np.mean(vals_case)
        mean_ctrl = np.mean(vals_ctrl)
        log2_fc = mean_case - mean_ctrl
        
        # 2. T-test (Welch's t-test, ä¸å‡è®¾æ–¹å·®ç›¸ç­‰)
        # æ•è·å¯èƒ½çš„é™¤é›¶é”™è¯¯
        try:
            t_stat, p_val = stats.ttest_ind(vals_case, vals_ctrl, equal_var=False)
        except:
            p_val = 1.0
        
        results.append({
            'Metabolite': feature,
            'Mean_Case': mean_case,
            'Mean_Ctrl': mean_ctrl,
            'Log2_FC': log2_fc,
            'P_Value': p_val
        })
        
    res_df = pd.DataFrame(results)
    
    # 3. FDR æ ¡æ­£ (Benjamini-Hochberg)
    res_df = res_df.dropna(subset=['P_Value'])
    if not res_df.empty:
        reject, pvals_corrected, _, _ = multipletests(res_df['P_Value'], method='fdr_bh')
        res_df['FDR'] = pvals_corrected
        res_df['-Log10_P'] = -np.log10(res_df['P_Value'])
    else:
        res_df['FDR'] = 1.0
        res_df['-Log10_P'] = 0
    
    return res_df

# ==========================================
# 3. ä¾§è¾¹æ ï¼šè¾“å…¥ä¸è®¾ç½®
# ==========================================

with st.sidebar:
    st.title("ğŸ› ï¸ åˆ†æè®¾ç½®")
    
    # 1. æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("1. ä¸Šä¼  CSV æ–‡ä»¶", type=["csv"], 
                                   help="æ ¼å¼è¦æ±‚ï¼šè¡Œ=æ ·æœ¬ï¼Œåˆ—=ä»£è°¢ç‰©ï¼Œå¿…é¡»åŒ…å«ä¸€åˆ—åˆ†ç»„åç§°")
    
    if uploaded_file is None:
        st.info("ğŸ‘‹ è¯·ä¸Šä¼ æ•°æ®ä»¥å¼€å§‹åˆ†æã€‚")
        st.markdown("**ç¤ºä¾‹æ•°æ®æ ¼å¼:**")
        st.markdown("""
        | Sample | Group | Glc | Lac | ... |
        | :--- | :--- | :--- | :--- | :--- |
        | S1 | Cancer | 10.5 | 2.3 | ... |
        | S2 | Healthy| 5.4 | 1.1 | ... |
        """)
        st.stop()
        
    # è¯»å–æ•°æ®
    raw_df = pd.read_csv(uploaded_file)
    st.success(f"åŠ è½½æˆåŠŸ: {raw_df.shape[0]} æ ·æœ¬, {raw_df.shape[1]} åˆ—")

    st.divider()

    # 2. åˆ†ç»„è®¾ç½®
    st.subheader("2. åˆ†ç»„é€‰æ‹©")
    # æ‰¾å‡ºæ‰€æœ‰éæ•°å€¼åˆ—ä½œä¸ºæ½œåœ¨çš„åˆ†ç»„åˆ—
    non_numeric_cols = raw_df.select_dtypes(exclude=[np.number]).columns.tolist()
    
    if not non_numeric_cols:
        st.error("æ•°æ®ä¸­æ²¡æœ‰æ‰¾åˆ°éæ•°å€¼åˆ—ï¼ˆä¾‹å¦‚ Groupï¼‰ï¼Œæ— æ³•è¿›è¡Œåˆ†ç»„åˆ†æã€‚")
        st.stop()
        
    group_col = st.selectbox("é€‰æ‹©åˆ†ç»„åˆ— (Group Column)", non_numeric_cols)
    
    unique_groups = raw_df[group_col].dropna().unique()
    if len(unique_groups) < 2:
        st.error("åˆ†ç»„åˆ—ä¸­çš„ç»„åˆ«å°‘äº 2 ä¸ªã€‚")
        st.stop()
        
    col_sel1, col_sel2 = st.columns(2)
    with col_sel1:
        case_group = st.selectbox("å®éªŒç»„ (Case)", unique_groups, index=0)
    with col_sel2:
        control_group = st.selectbox("å¯¹ç…§ç»„ (Ctrl)", unique_groups, index=min(1, len(unique_groups)-1))
        
    if case_group == control_group:
        st.warning("âš ï¸ å®éªŒç»„å’Œå¯¹ç…§ç»„ç›¸åŒï¼Œæ— æ³•åˆ†æå·®å¼‚ã€‚")
        st.stop()

    st.divider()

    # 3. å‚æ•°è®¾ç½®
    st.subheader("3. ç»Ÿè®¡å‚æ•°")
    use_log = st.checkbox("æ‰§è¡Œ Log2 è½¬æ¢", value=True, help="å¦‚æœä¸Šä¼ çš„æ•°æ®å·²ç»æ˜¯å–è¿‡å¯¹æ•°çš„ï¼Œè¯·å–æ¶ˆæ­¤é¡¹")
    p_thresh = st.number_input("P-value é˜ˆå€¼", value=0.05, step=0.01, format="%.3f")
    fc_thresh = st.number_input("Log2 FC é˜ˆå€¼ (ç»å¯¹å€¼)", value=1.0, step=0.1)


# ==========================================
# 4. ä¸»é€»è¾‘æ‰§è¡Œ
# ==========================================

# A. é¢„å¤„ç†
analysis_df, feature_cols = preprocess_data(raw_df, group_col, log_transform=use_log)

# ä»…ä¿ç•™é€‰ä¸­çš„ä¸¤ç»„æ ·æœ¬
sub_df = analysis_df[analysis_df[group_col].isin([case_group, control_group])].copy()

# B. ç»Ÿè®¡è®¡ç®—
stats_df = run_statistics(sub_df, group_col, case_group, control_group, feature_cols)

# æ ‡è®°æ˜¾è‘—æ€§
def get_sig_label(row):
    if row['P_Value'] < p_thresh and row['Log2_FC'] > fc_thresh:
        return 'Up'
    elif row['P_Value'] < p_thresh and row['Log2_FC'] < -fc_thresh:
        return 'Down'
    else:
        return 'NS'

stats_df['Significant'] = stats_df.apply(get_sig_label, axis=1)
color_map = {'Up': '#E64B35', 'Down': '#3C5488', 'NS': '#B0B0B0'}

# ==========================================
# 5. ç»“æœå±•ç¤º (Tabs)
# ==========================================

st.title("ğŸ§ª ä»£è°¢ç»„å­¦åˆ†ææŠ¥å‘Š")
st.markdown(f"**å¯¹æ¯”ç»„**: `{case_group}` vs `{control_group}` | **æ˜¾è‘—ç‰¹å¾**: `{len(stats_df[stats_df['Significant'] != 'NS'])}` ä¸ª")

tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ“Š PCA åˆ†æ", 
    "ğŸ¯ PLS-DA åˆ†æ", 
    "ğŸŒ‹ ç«å±±å›¾", 
    "ğŸ“¦ è¯¦æƒ… (Boxplot)", 
    "ğŸ“‘ æ•°æ®è¡¨"
])

# --- TAB 1: PCA ---
with tab1:
    st.markdown("### ä¸»æˆåˆ†åˆ†æ (PCA)")
    col_pca1, col_pca2 = st.columns([3, 1])
    
    with col_pca1:
        X = sub_df[feature_cols]
        # PCA å‰å¿…é¡»æ ‡å‡†åŒ– (Mean=0, Var=1)
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        pca = PCA(n_components=2)
        components = pca.fit_transform(X_scaled)
        
        pca_df = pd.DataFrame(components, columns=['PC1', 'PC2'])
        pca_df['Group'] = sub_df[group_col].values
        
        var_exp = pca.explained_variance_ratio_
        
        fig_pca = px.scatter(pca_df, x='PC1', y='PC2', color='Group',
                             title=f"PCA Score Plot (PC1: {var_exp[0]:.1%}, PC2: {var_exp[1]:.1%})",
                             template="simple_white", width=700, height=500)
        st.plotly_chart(fig_pca, use_container_width=True)
        
    with col_pca2:
        st.info("PCA æ˜¯ä¸€ç§æ— ç›‘ç£åˆ†æï¼Œç”¨äºè§‚å¯Ÿæ ·æœ¬çš„è‡ªç„¶èšç±»æƒ…å†µã€‚å¦‚æœæ ·æœ¬æŒ‰ç…§ç»„åˆ«è‡ªç„¶åˆ†å¼€ï¼Œè¯´æ˜ç»„é—´å­˜åœ¨æ˜¾è‘—çš„æ•´ä½“ä»£è°¢å·®å¼‚ã€‚")

# --- TAB 2: PLS-DA ---
with tab2:
    st.markdown("### åæœ€å°äºŒä¹˜åˆ¤åˆ«åˆ†æ (PLS-DA)")
    col_pls1, col_pls2 = st.columns([3, 1])
    
    with col_pls1:
        # å‡†å¤‡æ•°æ®
        X_pls = sub_df[feature_cols]
        y_pls = pd.factorize(sub_df[group_col])[0]
        
        scaler_pls = StandardScaler()
        X_pls_scaled = scaler_pls.fit_transform(X_pls)
        
        # å»ºç«‹ PLS æ¨¡å‹
        pls = PLSRegression(n_components=2)
        pls.fit(X_pls_scaled, y_pls)
        
        # 1. Score Plot
        pls_scores = pd.DataFrame(pls.x_scores_, columns=['Comp 1', 'Comp 2'])
        pls_scores['Group'] = sub_df[group_col].values
        
        fig_pls = px.scatter(pls_scores, x='Comp 1', y='Comp 2', color='Group',
                             title="PLS-DA Score Plot", template="simple_white")
        st.plotly_chart(fig_pls, use_container_width=True)
        
        # 2. VIP Scores
        st.markdown("#### å˜é‡é‡è¦æ€§æŠ•å½± (VIP Scores)")
        vip_vals = calculate_vips(pls)
        vip_df = pd.DataFrame({'Metabolite': feature_cols, 'VIP': vip_vals})
        vip_df = vip_df.sort_values('VIP', ascending=False).head(15)
        
        fig_vip = px.bar(vip_df, x='VIP', y='Metabolite', orientation='h',
                         color='VIP', title="Top 15 Important Features (VIP)",
                         color_continuous_scale='Teal', template="simple_white")
        fig_vip.update_layout(yaxis={'categoryorder':'total ascending'})
        st.plotly_chart(fig_vip, use_container_width=True)
        
    with col_pls2:
        st.info("PLS-DA æ˜¯ä¸€ç§æœ‰ç›‘ç£åˆ†æï¼Œå¼ºè¡Œå¯»æ‰¾èƒ½æœ€å¤§åŒ–åŒºåˆ†ç»„åˆ«çš„æ–¹å‘ã€‚\n\n**VIP Score**: å€¼å¤§äº 1 é€šå¸¸è¢«è®¤ä¸ºå¯¹åˆ†ç»„è´¡çŒ®æ˜¾è‘—ã€‚")

# --- TAB 3: Volcano Plot ---
with tab3:
    col_vol1, col_vol2 = st.columns([3, 1])
    with col_vol1:
        fig_vol = px.scatter(stats_df, x="Log2_FC", y="-Log10_P", color="Significant",
                             color_discrete_map=color_map,
                             hover_data=["Metabolite", "P_Value", "FDR"],
                             title="Volcano Plot (P-value vs Fold Change)",
                             template="simple_white")
        
        # è¾…åŠ©çº¿
        fig_vol.add_hline(y=-np.log10(p_thresh), line_dash="dash", line_color="gray")
        fig_vol.add_vline(x=fc_thresh, line_dash="dash", line_color="gray")
        fig_vol.add_vline(x=-fc_thresh, line_dash="dash", line_color="gray")
        
        st.plotly_chart(fig_vol, use_container_width=True)
        
    with col_vol2:
        st.write("#### ç­›é€‰ç»Ÿè®¡")
        st.metric("ä¸Šè°ƒ (Up)", len(stats_df[stats_df['Significant']=='Up']))
        st.metric("ä¸‹è°ƒ (Down)", len(stats_df[stats_df['Significant']=='Down']))
        st.caption(f"é˜ˆå€¼è®¾å®š: P < {p_thresh}, |Log2FC| > {fc_thresh}")

# --- TAB 4: Box Plot ---
with tab4:
    st.markdown("### å•ä¸ªä»£è°¢ç‰©è¡¨è¾¾æ°´å¹³")
    
    # ä¼˜å…ˆæ˜¾ç¤ºæ˜¾è‘—å·®å¼‚çš„ä»£è°¢ç‰©
    sig_feats = stats_df[stats_df['Significant'] != 'NS']['Metabolite'].tolist()
    all_feats = sorted(sub_df[feature_cols].columns.tolist())
    
    # ä¸‹æ‹‰æ¡†
    box_feat = st.selectbox("é€‰æ‹©ä»£è°¢ç‰©æŸ¥çœ‹:", sig_feats if sig_feats else all_feats)
    
    if box_feat:
        # å‡†å¤‡ç”»å›¾æ•°æ®
        plot_data = sub_df[[group_col, box_feat]].copy()
        
        fig_box = px.box(plot_data, x=group_col, y=box_feat, color=group_col,
                         points='all', # æ˜¾ç¤ºæ•£ç‚¹
                         title=f"Expression of {box_feat}",
                         template="simple_white")
        st.plotly_chart(fig_box, use_container_width=True)

# --- TAB 5: Results Table ---
with tab5:
    st.markdown("### è¯¦ç»†ç»Ÿè®¡ç»“æœè¡¨")
    
    # æ ¼å¼åŒ–è¡¨æ ¼ç”¨äºæ˜¾ç¤º
    out_df = stats_df.sort_values("P_Value").copy()
    
    st.dataframe(
        out_df.style.format({
            "Mean_Case": "{:.2f}", "Mean_Ctrl": "{:.2f}",
            "Log2_FC": "{:.2f}", "P_Value": "{:.4f}", 
            "FDR": "{:.4f}", "-Log10_P": "{:.2f}"
        }).background_gradient(subset=['P_Value'], cmap="Reds_r", vmin=0, vmax=0.05),
        use_container_width=True
    )
    
    # ä¸‹è½½æŒ‰é’®
    csv_data = out_df.to_csv(index=False).encode('utf-8')
    st.download_button("ğŸ“¥ ä¸‹è½½å®Œæ•´ç»“æœ (CSV)", data=csv_data, 
                       file_name="metabolomics_results.csv", mime="text/csv")

